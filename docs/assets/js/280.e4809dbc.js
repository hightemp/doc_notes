(window.webpackJsonp=window.webpackJsonp||[]).push([[280],{550:function(t,s,a){"use strict";a.r(s);var e=a(14),n=Object(e.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"what-are-scrapy-items-why-should-we-use-them-​"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#what-are-scrapy-items-why-should-we-use-them-​"}},[t._v("#")]),t._v(" What Are Scrapy Items & Why Should We Use Them?"),s("a",{attrs:{href:"https://scrapeops.io/python-scrapy-playbook/scrapy-items/#what-are-scrapy-items--why-should-we-use-them",title:"Direct link to heading",target:"_blank",rel:"noopener noreferrer"}},[t._v("​"),s("OutboundLink")],1)]),t._v(" "),s("p",[s("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/items.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Scrapy Items"),s("OutboundLink")],1),t._v(" are a predefined data structure that holds your data.")]),t._v(" "),s("p",[t._v("Instead of yielding your scraped data in the form of a dictionary for example, you define a Item schema beforehand in your "),s("code",[t._v("items.py")]),t._v(" file and use this schema when scraping data.")]),t._v(" "),s("p",[t._v("This enables you to quickly and easily check what structured data you are collecting in your project, it will raise exceptions if you try and create incorrect data with your Item.")]),t._v(" "),s("p",[t._v("Because of this, using Scrapy Items have a number of advantages:")]),t._v(" "),s("ul",[s("li",[t._v("Structures your data and gives it a clear schema.")]),t._v(" "),s("li",[t._v("Enables you to easily clean and process your scraped data.")]),t._v(" "),s("li",[t._v("Enables you to validate, deduplicate and monitor your data feeds.")]),t._v(" "),s("li",[t._v("Enables you to easily store and export your data with "),s("a",{attrs:{href:"https://docs.scrapy.org/en/1.8/topics/feed-exports.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Scrapy Feed Exports"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("li",[t._v("Makes using "),s("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/item-pipeline.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Scrapy Item Pipelines"),s("OutboundLink")],1),t._v(" & "),s("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/loaders.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Item Loaders"),s("OutboundLink")],1),t._v(".")])]),t._v(" "),s("p",[t._v("Scrapy supports multiple types of data formats that are automatically converted into Scrapy Items when yielded:")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/items.html#dict-items",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dictionaries"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/items.html#dataclass-items",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dataclass Objects"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/items.html#attrs-items",target:"_blank",rel:"noopener noreferrer"}},[t._v("Attrs Objects"),s("OutboundLink")],1)])]),t._v(" "),s("p",[t._v("However, defining your own "),s("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/items.html#item-objects",target:"_blank",rel:"noopener noreferrer"}},[s("strong",[t._v("Item object")]),s("OutboundLink")],1),t._v(" in your "),s("code",[t._v("items.py")]),t._v(" file is normally the best option.")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"how-to-integrate-items-into-your-spiders​"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#how-to-integrate-items-into-your-spiders​"}},[t._v("#")]),t._v(" How To Integrate Items Into Your Spiders"),s("a",{attrs:{href:"https://scrapeops.io/python-scrapy-playbook/scrapy-items/#how-to-integrate-items-into-your-spiders",title:"Direct link to heading",target:"_blank",rel:"noopener noreferrer"}},[t._v("​"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("Creating an "),s("strong",[t._v("Item")]),t._v(" in Scrapy is very straight forward. Simply open your "),s("code",[t._v("items.py")]),t._v(" file and define the data you would like to scrape by inheriting from the Scrapy Item class.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# items.py  ")]),t._v("\n  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("item "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Field  \n  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("QuoteItem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  \ntext "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \ntags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \nauthor "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Then inside in your spider, instead of yielding a dictionary you would create a new Item with the scraped data before yielding it.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# items.py  ")]),t._v("\n  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scrapy  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" items_demo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" QuoteItem  \n  \n  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("QuotesSpider")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scrapy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Spider"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  \nname "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'quotes'")]),t._v("  \n  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("start_requests")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  \nurl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://quotes.toscrape.com/'")]),t._v("  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" scrapy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Request"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" callback"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  \nquote_item "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" QuoteItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" quote "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" response"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'div.quote'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  \nquote_item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" quote"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'span.text::text'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \nquote_item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'author'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" quote"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'small.author::text'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \nquote_item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tags'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" quote"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'div.tags a.tag::text'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getall"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" quote_item\n")])])]),s("p",[t._v("Now, all your scraped data will be contained in the structured "),s("code",[t._v("QuoteItem")]),t._v(" we created which can then be sent through any active "),s("strong",[t._v("Item Pipelines")]),t._v(" to clean, validate and store your data.")]),t._v(" "),s("hr")])}),[],!1,null,null,null);s.default=n.exports}}]);