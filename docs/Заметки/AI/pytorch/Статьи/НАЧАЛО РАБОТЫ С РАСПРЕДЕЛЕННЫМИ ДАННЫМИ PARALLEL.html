<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>VuePress</title>
    <meta name="generator" content="VuePress 1.9.9">
    
    <meta name="description" content="">
    
    <link rel="preload" href="/assets/css/0.styles.e8e4f3a3.css" as="style"><link rel="preload" href="/assets/js/app.dec9f71a.js" as="script"><link rel="preload" href="/assets/js/2.733019b2.js" as="script"><link rel="preload" href="/assets/js/28.f9359f93.js" as="script"><link rel="prefetch" href="/assets/js/10.3c45a7ae.js"><link rel="prefetch" href="/assets/js/100.945d3075.js"><link rel="prefetch" href="/assets/js/101.c304dc04.js"><link rel="prefetch" href="/assets/js/102.c4ea246f.js"><link rel="prefetch" href="/assets/js/103.3fa17de4.js"><link rel="prefetch" href="/assets/js/104.10b346d7.js"><link rel="prefetch" href="/assets/js/105.37af8494.js"><link rel="prefetch" href="/assets/js/106.580b656c.js"><link rel="prefetch" href="/assets/js/107.bbf35ca8.js"><link rel="prefetch" href="/assets/js/108.ef31db2d.js"><link rel="prefetch" href="/assets/js/109.e0b67167.js"><link rel="prefetch" href="/assets/js/11.2369400d.js"><link rel="prefetch" href="/assets/js/110.f5f9eacf.js"><link rel="prefetch" href="/assets/js/111.a566b9a5.js"><link rel="prefetch" href="/assets/js/112.9872e360.js"><link rel="prefetch" href="/assets/js/113.55c7a352.js"><link rel="prefetch" href="/assets/js/114.12ee164e.js"><link rel="prefetch" href="/assets/js/115.1fb2093f.js"><link rel="prefetch" href="/assets/js/116.d46141e0.js"><link rel="prefetch" href="/assets/js/117.d60c7d89.js"><link rel="prefetch" href="/assets/js/118.c3b7612c.js"><link rel="prefetch" href="/assets/js/119.10367318.js"><link rel="prefetch" href="/assets/js/12.286d27d6.js"><link rel="prefetch" href="/assets/js/120.be792f55.js"><link rel="prefetch" href="/assets/js/121.9b95acc0.js"><link rel="prefetch" href="/assets/js/122.eaab2843.js"><link rel="prefetch" href="/assets/js/123.cc552dc6.js"><link rel="prefetch" href="/assets/js/124.cce7d459.js"><link rel="prefetch" href="/assets/js/125.c5c5f203.js"><link rel="prefetch" href="/assets/js/126.9fb20891.js"><link rel="prefetch" href="/assets/js/127.06235e8b.js"><link rel="prefetch" href="/assets/js/128.a7d21829.js"><link rel="prefetch" href="/assets/js/129.cf5cb2cd.js"><link rel="prefetch" href="/assets/js/13.47981763.js"><link rel="prefetch" href="/assets/js/130.53cfb33f.js"><link rel="prefetch" href="/assets/js/131.3a8b27b3.js"><link rel="prefetch" href="/assets/js/132.872dde3d.js"><link rel="prefetch" href="/assets/js/133.82865bbc.js"><link rel="prefetch" href="/assets/js/134.f3b5d42f.js"><link rel="prefetch" href="/assets/js/135.4c91805f.js"><link rel="prefetch" href="/assets/js/136.dcb8f9e2.js"><link rel="prefetch" href="/assets/js/137.07d2bab8.js"><link rel="prefetch" href="/assets/js/138.ea94033d.js"><link rel="prefetch" href="/assets/js/139.79ad652e.js"><link rel="prefetch" href="/assets/js/14.2f49c0ab.js"><link rel="prefetch" href="/assets/js/140.d6518035.js"><link rel="prefetch" href="/assets/js/141.6b166b92.js"><link rel="prefetch" href="/assets/js/142.c4466c2b.js"><link rel="prefetch" href="/assets/js/143.141061b6.js"><link rel="prefetch" href="/assets/js/144.5cee20dc.js"><link rel="prefetch" href="/assets/js/145.97956c27.js"><link rel="prefetch" href="/assets/js/146.23cb4066.js"><link rel="prefetch" href="/assets/js/147.bb1e6c1a.js"><link rel="prefetch" href="/assets/js/148.a5bd7077.js"><link rel="prefetch" href="/assets/js/149.57694ad8.js"><link rel="prefetch" href="/assets/js/15.0cb65b1e.js"><link rel="prefetch" href="/assets/js/150.faf7fa9f.js"><link rel="prefetch" href="/assets/js/151.2ee47c84.js"><link rel="prefetch" href="/assets/js/152.9a82c536.js"><link rel="prefetch" href="/assets/js/153.5bd8c4a5.js"><link rel="prefetch" href="/assets/js/154.7cdc00ab.js"><link rel="prefetch" href="/assets/js/155.a2a1c88e.js"><link rel="prefetch" href="/assets/js/156.92796b90.js"><link rel="prefetch" href="/assets/js/157.f247bf22.js"><link rel="prefetch" href="/assets/js/158.eaeb08c7.js"><link rel="prefetch" href="/assets/js/159.555a6593.js"><link rel="prefetch" href="/assets/js/16.6fd62cc7.js"><link rel="prefetch" href="/assets/js/160.bf19eb80.js"><link rel="prefetch" href="/assets/js/161.7ce1d12b.js"><link rel="prefetch" href="/assets/js/162.f6dc5f4b.js"><link rel="prefetch" href="/assets/js/163.16df5c09.js"><link rel="prefetch" href="/assets/js/164.bdd3ee47.js"><link rel="prefetch" href="/assets/js/165.ba85290c.js"><link rel="prefetch" href="/assets/js/166.6b1a560c.js"><link rel="prefetch" href="/assets/js/167.59b9445e.js"><link rel="prefetch" href="/assets/js/168.69cc230d.js"><link rel="prefetch" href="/assets/js/169.55882eed.js"><link rel="prefetch" href="/assets/js/17.94447945.js"><link rel="prefetch" href="/assets/js/170.129124fc.js"><link rel="prefetch" href="/assets/js/171.cf1a85f9.js"><link rel="prefetch" href="/assets/js/172.36f3cdfc.js"><link rel="prefetch" href="/assets/js/173.cddbfa1b.js"><link rel="prefetch" href="/assets/js/174.a32fe0ad.js"><link rel="prefetch" href="/assets/js/175.c1414217.js"><link rel="prefetch" href="/assets/js/176.a678371f.js"><link rel="prefetch" href="/assets/js/177.583b2ac2.js"><link rel="prefetch" href="/assets/js/178.6dd3c8d6.js"><link rel="prefetch" href="/assets/js/179.dac91cd2.js"><link rel="prefetch" href="/assets/js/18.75e97365.js"><link rel="prefetch" href="/assets/js/180.9dfd9728.js"><link rel="prefetch" href="/assets/js/181.9afd854f.js"><link rel="prefetch" href="/assets/js/182.d0dbacf1.js"><link rel="prefetch" href="/assets/js/183.1dbeb096.js"><link rel="prefetch" href="/assets/js/184.27b34aeb.js"><link rel="prefetch" href="/assets/js/185.13641773.js"><link rel="prefetch" href="/assets/js/186.d79c8675.js"><link rel="prefetch" href="/assets/js/187.484bb501.js"><link rel="prefetch" href="/assets/js/188.f73564d2.js"><link rel="prefetch" href="/assets/js/189.25f0971d.js"><link rel="prefetch" href="/assets/js/19.9abedc68.js"><link rel="prefetch" href="/assets/js/190.00b862d0.js"><link rel="prefetch" href="/assets/js/191.a255f76b.js"><link rel="prefetch" href="/assets/js/192.6b6a1c68.js"><link rel="prefetch" href="/assets/js/193.916ffb26.js"><link rel="prefetch" href="/assets/js/194.2c928fb3.js"><link rel="prefetch" href="/assets/js/195.20a9fc51.js"><link rel="prefetch" href="/assets/js/196.f2abf901.js"><link rel="prefetch" href="/assets/js/197.871f3d6a.js"><link rel="prefetch" href="/assets/js/198.3ea5cf81.js"><link rel="prefetch" href="/assets/js/199.3f37d030.js"><link rel="prefetch" href="/assets/js/20.1c33d690.js"><link rel="prefetch" href="/assets/js/200.7e20b89c.js"><link rel="prefetch" href="/assets/js/201.ae9ed05e.js"><link rel="prefetch" href="/assets/js/202.d686563a.js"><link rel="prefetch" href="/assets/js/203.5a9ac59e.js"><link rel="prefetch" href="/assets/js/204.4abf0169.js"><link rel="prefetch" href="/assets/js/205.94fe861e.js"><link rel="prefetch" href="/assets/js/206.76e93465.js"><link rel="prefetch" href="/assets/js/207.92c5e562.js"><link rel="prefetch" href="/assets/js/208.79f31d54.js"><link rel="prefetch" href="/assets/js/209.eb534898.js"><link rel="prefetch" href="/assets/js/21.de3ad1f7.js"><link rel="prefetch" href="/assets/js/210.38242c09.js"><link rel="prefetch" href="/assets/js/211.ca8aa9a4.js"><link rel="prefetch" href="/assets/js/212.189fa4e2.js"><link rel="prefetch" href="/assets/js/213.239f2bd6.js"><link rel="prefetch" href="/assets/js/214.b1a9ece6.js"><link rel="prefetch" href="/assets/js/215.823222d2.js"><link rel="prefetch" href="/assets/js/216.6c3fbaad.js"><link rel="prefetch" href="/assets/js/217.c2bd084b.js"><link rel="prefetch" href="/assets/js/218.7ad57fcc.js"><link rel="prefetch" href="/assets/js/219.4ef0266b.js"><link rel="prefetch" href="/assets/js/22.a45331de.js"><link rel="prefetch" href="/assets/js/220.e9fd4c5f.js"><link rel="prefetch" href="/assets/js/221.0b0f609a.js"><link rel="prefetch" href="/assets/js/222.ff25599e.js"><link rel="prefetch" href="/assets/js/223.8319d2d0.js"><link rel="prefetch" href="/assets/js/224.da5c4d3e.js"><link rel="prefetch" href="/assets/js/225.9378291a.js"><link rel="prefetch" href="/assets/js/226.0d8b2ef5.js"><link rel="prefetch" href="/assets/js/227.82cd2e2d.js"><link rel="prefetch" href="/assets/js/228.db49009d.js"><link rel="prefetch" href="/assets/js/229.e735fec4.js"><link rel="prefetch" href="/assets/js/23.de5de683.js"><link rel="prefetch" href="/assets/js/230.47e7011d.js"><link rel="prefetch" href="/assets/js/231.7f0e5905.js"><link rel="prefetch" href="/assets/js/232.a6cb0759.js"><link rel="prefetch" href="/assets/js/233.09bbd53b.js"><link rel="prefetch" href="/assets/js/234.b9341514.js"><link rel="prefetch" href="/assets/js/235.3563b4bf.js"><link rel="prefetch" href="/assets/js/236.7d5da9ca.js"><link rel="prefetch" href="/assets/js/237.c7a693f3.js"><link rel="prefetch" href="/assets/js/238.803df100.js"><link rel="prefetch" href="/assets/js/239.ef64fcf2.js"><link rel="prefetch" href="/assets/js/24.b363b117.js"><link rel="prefetch" href="/assets/js/240.2befed40.js"><link rel="prefetch" href="/assets/js/241.10a01506.js"><link rel="prefetch" href="/assets/js/242.3b369ac8.js"><link rel="prefetch" href="/assets/js/243.31958eb9.js"><link rel="prefetch" href="/assets/js/244.b9489a7d.js"><link rel="prefetch" href="/assets/js/245.b9b191e5.js"><link rel="prefetch" href="/assets/js/246.18aeb9f6.js"><link rel="prefetch" href="/assets/js/247.39cc492f.js"><link rel="prefetch" href="/assets/js/248.b08e232c.js"><link rel="prefetch" href="/assets/js/249.6d660682.js"><link rel="prefetch" href="/assets/js/25.5e2fe982.js"><link rel="prefetch" href="/assets/js/250.235cee85.js"><link rel="prefetch" href="/assets/js/251.66edac43.js"><link rel="prefetch" href="/assets/js/252.28ec4821.js"><link rel="prefetch" href="/assets/js/253.828cd3b6.js"><link rel="prefetch" href="/assets/js/254.6b19e7b7.js"><link rel="prefetch" href="/assets/js/255.7808e23e.js"><link rel="prefetch" href="/assets/js/256.33572d7d.js"><link rel="prefetch" href="/assets/js/257.8044242f.js"><link rel="prefetch" href="/assets/js/258.2eb93b76.js"><link rel="prefetch" href="/assets/js/259.6d222e72.js"><link rel="prefetch" href="/assets/js/26.b3336cf9.js"><link rel="prefetch" href="/assets/js/260.b3345d12.js"><link rel="prefetch" href="/assets/js/261.6f64a148.js"><link rel="prefetch" href="/assets/js/262.283e9e13.js"><link rel="prefetch" href="/assets/js/263.10934b95.js"><link rel="prefetch" href="/assets/js/264.52a220d8.js"><link rel="prefetch" href="/assets/js/265.3099a02f.js"><link rel="prefetch" href="/assets/js/266.d093c25c.js"><link rel="prefetch" href="/assets/js/267.ffd0ea6c.js"><link rel="prefetch" href="/assets/js/268.71a5b2a5.js"><link rel="prefetch" href="/assets/js/269.e02d0a12.js"><link rel="prefetch" href="/assets/js/27.bacb7462.js"><link rel="prefetch" href="/assets/js/270.717bdd21.js"><link rel="prefetch" href="/assets/js/271.ceef3037.js"><link rel="prefetch" href="/assets/js/272.b040f2d8.js"><link rel="prefetch" href="/assets/js/273.e06cd101.js"><link rel="prefetch" href="/assets/js/274.9c206962.js"><link rel="prefetch" href="/assets/js/275.46ae609d.js"><link rel="prefetch" href="/assets/js/276.16e277a9.js"><link rel="prefetch" href="/assets/js/277.fcb15734.js"><link rel="prefetch" href="/assets/js/278.0cc37dab.js"><link rel="prefetch" href="/assets/js/279.55e66e78.js"><link rel="prefetch" href="/assets/js/280.e4809dbc.js"><link rel="prefetch" href="/assets/js/281.0889dba5.js"><link rel="prefetch" href="/assets/js/282.459e1cec.js"><link rel="prefetch" href="/assets/js/283.0b2d1fb1.js"><link rel="prefetch" href="/assets/js/284.ffe54aa9.js"><link rel="prefetch" href="/assets/js/285.d9ed13ce.js"><link rel="prefetch" href="/assets/js/286.5574e754.js"><link rel="prefetch" href="/assets/js/287.f9187311.js"><link rel="prefetch" href="/assets/js/288.cd2b56c3.js"><link rel="prefetch" href="/assets/js/289.8552c742.js"><link rel="prefetch" href="/assets/js/29.9a6765b0.js"><link rel="prefetch" href="/assets/js/290.7d0673a7.js"><link rel="prefetch" href="/assets/js/291.5c185731.js"><link rel="prefetch" href="/assets/js/292.fab6d535.js"><link rel="prefetch" href="/assets/js/293.457fd94a.js"><link rel="prefetch" href="/assets/js/294.748e6f29.js"><link rel="prefetch" href="/assets/js/295.99a4bc36.js"><link rel="prefetch" href="/assets/js/296.f02a6f54.js"><link rel="prefetch" href="/assets/js/297.a2899d72.js"><link rel="prefetch" href="/assets/js/298.8e5a5ef7.js"><link rel="prefetch" href="/assets/js/299.eff3af7f.js"><link rel="prefetch" href="/assets/js/3.e54eedac.js"><link rel="prefetch" href="/assets/js/30.8899ae33.js"><link rel="prefetch" href="/assets/js/300.ea47d06a.js"><link rel="prefetch" href="/assets/js/301.0f51c16c.js"><link rel="prefetch" href="/assets/js/302.0672bd76.js"><link rel="prefetch" href="/assets/js/303.99557654.js"><link rel="prefetch" href="/assets/js/304.069ee3f6.js"><link rel="prefetch" href="/assets/js/305.bbbcb69f.js"><link rel="prefetch" href="/assets/js/306.458f04ac.js"><link rel="prefetch" href="/assets/js/307.d8a121f6.js"><link rel="prefetch" href="/assets/js/308.4e353bdf.js"><link rel="prefetch" href="/assets/js/309.41135b53.js"><link rel="prefetch" href="/assets/js/31.907a86ff.js"><link rel="prefetch" href="/assets/js/310.d9900cca.js"><link rel="prefetch" href="/assets/js/311.4c8d1049.js"><link rel="prefetch" href="/assets/js/312.e461412c.js"><link rel="prefetch" href="/assets/js/313.b481fec8.js"><link rel="prefetch" href="/assets/js/314.7c9d7531.js"><link rel="prefetch" href="/assets/js/315.493dd60b.js"><link rel="prefetch" href="/assets/js/316.b892fdb3.js"><link rel="prefetch" href="/assets/js/317.0488dbc0.js"><link rel="prefetch" href="/assets/js/318.e3024dfc.js"><link rel="prefetch" href="/assets/js/319.cbeb3017.js"><link rel="prefetch" href="/assets/js/32.566fa885.js"><link rel="prefetch" href="/assets/js/320.6bbdcb6f.js"><link rel="prefetch" href="/assets/js/321.393ba5b9.js"><link rel="prefetch" href="/assets/js/322.e1ac37db.js"><link rel="prefetch" href="/assets/js/323.ecada34d.js"><link rel="prefetch" href="/assets/js/324.b5a78957.js"><link rel="prefetch" href="/assets/js/325.78a07f6c.js"><link rel="prefetch" href="/assets/js/326.18acb16b.js"><link rel="prefetch" href="/assets/js/327.f1fdf85e.js"><link rel="prefetch" href="/assets/js/328.cb4e6a88.js"><link rel="prefetch" href="/assets/js/329.7064a56d.js"><link rel="prefetch" href="/assets/js/33.089e8d27.js"><link rel="prefetch" href="/assets/js/330.eb5d365c.js"><link rel="prefetch" href="/assets/js/331.7413cc1f.js"><link rel="prefetch" href="/assets/js/332.268810a7.js"><link rel="prefetch" href="/assets/js/333.14b9f266.js"><link rel="prefetch" href="/assets/js/334.79f3c205.js"><link rel="prefetch" href="/assets/js/335.4c1fa2f4.js"><link rel="prefetch" href="/assets/js/336.2a555b98.js"><link rel="prefetch" href="/assets/js/337.c8d1a7eb.js"><link rel="prefetch" href="/assets/js/338.027e65ab.js"><link rel="prefetch" href="/assets/js/339.e913eb02.js"><link rel="prefetch" href="/assets/js/34.5cbcf358.js"><link rel="prefetch" href="/assets/js/340.ccfb0701.js"><link rel="prefetch" href="/assets/js/341.2bf59012.js"><link rel="prefetch" href="/assets/js/342.43214bf6.js"><link rel="prefetch" href="/assets/js/343.860e5acc.js"><link rel="prefetch" href="/assets/js/344.af2b1413.js"><link rel="prefetch" href="/assets/js/345.6dfaf1a7.js"><link rel="prefetch" href="/assets/js/346.4bccf6c8.js"><link rel="prefetch" href="/assets/js/347.c42d14ab.js"><link rel="prefetch" href="/assets/js/348.f00c8f2c.js"><link rel="prefetch" href="/assets/js/349.47f740a6.js"><link rel="prefetch" href="/assets/js/35.e9eab731.js"><link rel="prefetch" href="/assets/js/350.30d3e969.js"><link rel="prefetch" href="/assets/js/351.1295792b.js"><link rel="prefetch" href="/assets/js/352.363b9177.js"><link rel="prefetch" href="/assets/js/353.601c5370.js"><link rel="prefetch" href="/assets/js/354.047a1d22.js"><link rel="prefetch" href="/assets/js/355.3f32b1c2.js"><link rel="prefetch" href="/assets/js/356.1816f3c9.js"><link rel="prefetch" href="/assets/js/357.c81f86b9.js"><link rel="prefetch" href="/assets/js/358.a2fdfdd3.js"><link rel="prefetch" href="/assets/js/359.a5e1fa6a.js"><link rel="prefetch" href="/assets/js/36.a655d7e3.js"><link rel="prefetch" href="/assets/js/360.cecc875b.js"><link rel="prefetch" href="/assets/js/361.c8915051.js"><link rel="prefetch" href="/assets/js/362.5c07a421.js"><link rel="prefetch" href="/assets/js/363.adc2e062.js"><link rel="prefetch" href="/assets/js/364.f0f96ce6.js"><link rel="prefetch" href="/assets/js/365.a4a5cc32.js"><link rel="prefetch" href="/assets/js/366.4dbc70ea.js"><link rel="prefetch" href="/assets/js/367.626ad073.js"><link rel="prefetch" href="/assets/js/368.033096e1.js"><link rel="prefetch" href="/assets/js/369.ba1ab9e8.js"><link rel="prefetch" href="/assets/js/37.46464e89.js"><link rel="prefetch" href="/assets/js/370.5a4de7d9.js"><link rel="prefetch" href="/assets/js/371.8e19304c.js"><link rel="prefetch" href="/assets/js/372.00d24aa5.js"><link rel="prefetch" href="/assets/js/373.5d43f401.js"><link rel="prefetch" href="/assets/js/374.eeea88f6.js"><link rel="prefetch" href="/assets/js/38.5710d281.js"><link rel="prefetch" href="/assets/js/39.22cd4ce1.js"><link rel="prefetch" href="/assets/js/4.d12742be.js"><link rel="prefetch" href="/assets/js/40.ac785c50.js"><link rel="prefetch" href="/assets/js/41.e52206b8.js"><link rel="prefetch" href="/assets/js/42.fbd0e0ce.js"><link rel="prefetch" href="/assets/js/43.e0830f9d.js"><link rel="prefetch" href="/assets/js/44.23c6ba45.js"><link rel="prefetch" href="/assets/js/45.b9a24221.js"><link rel="prefetch" href="/assets/js/46.83cf1192.js"><link rel="prefetch" href="/assets/js/47.220fb3ae.js"><link rel="prefetch" href="/assets/js/48.130760fa.js"><link rel="prefetch" href="/assets/js/49.d6f4ded1.js"><link rel="prefetch" href="/assets/js/5.216cae74.js"><link rel="prefetch" href="/assets/js/50.9cbfe92f.js"><link rel="prefetch" href="/assets/js/51.3446f694.js"><link rel="prefetch" href="/assets/js/52.72649f7e.js"><link rel="prefetch" href="/assets/js/53.6f0f60f7.js"><link rel="prefetch" href="/assets/js/54.a1d865f2.js"><link rel="prefetch" href="/assets/js/55.474dea5b.js"><link rel="prefetch" href="/assets/js/56.34577514.js"><link rel="prefetch" href="/assets/js/57.f6fc2205.js"><link rel="prefetch" href="/assets/js/58.a47a439e.js"><link rel="prefetch" href="/assets/js/59.06b99b85.js"><link rel="prefetch" href="/assets/js/6.2d0a63f8.js"><link rel="prefetch" href="/assets/js/60.20e5a404.js"><link rel="prefetch" href="/assets/js/61.06eb00d3.js"><link rel="prefetch" href="/assets/js/62.ef43b805.js"><link rel="prefetch" href="/assets/js/63.96d7abec.js"><link rel="prefetch" href="/assets/js/64.828a623b.js"><link rel="prefetch" href="/assets/js/65.8270a1b7.js"><link rel="prefetch" href="/assets/js/66.3da895e0.js"><link rel="prefetch" href="/assets/js/67.30e83906.js"><link rel="prefetch" href="/assets/js/68.c5db27df.js"><link rel="prefetch" href="/assets/js/69.561fe0b5.js"><link rel="prefetch" href="/assets/js/7.929bde26.js"><link rel="prefetch" href="/assets/js/70.0b3415d2.js"><link rel="prefetch" href="/assets/js/71.4351b7f3.js"><link rel="prefetch" href="/assets/js/72.ce1be2c6.js"><link rel="prefetch" href="/assets/js/73.d9f4c187.js"><link rel="prefetch" href="/assets/js/74.b8e2035e.js"><link rel="prefetch" href="/assets/js/75.f721109d.js"><link rel="prefetch" href="/assets/js/76.1fffa028.js"><link rel="prefetch" href="/assets/js/77.392e6f02.js"><link rel="prefetch" href="/assets/js/78.788b59e8.js"><link rel="prefetch" href="/assets/js/79.0118ba12.js"><link rel="prefetch" href="/assets/js/8.81ac42c3.js"><link rel="prefetch" href="/assets/js/80.41299197.js"><link rel="prefetch" href="/assets/js/81.d5c7efcc.js"><link rel="prefetch" href="/assets/js/82.0686785a.js"><link rel="prefetch" href="/assets/js/83.1c3c9afc.js"><link rel="prefetch" href="/assets/js/84.77cbfea0.js"><link rel="prefetch" href="/assets/js/85.a72511bb.js"><link rel="prefetch" href="/assets/js/86.ee7de8e7.js"><link rel="prefetch" href="/assets/js/87.6725a162.js"><link rel="prefetch" href="/assets/js/88.de798e46.js"><link rel="prefetch" href="/assets/js/89.e3b19fd4.js"><link rel="prefetch" href="/assets/js/9.0286aa6e.js"><link rel="prefetch" href="/assets/js/90.15a0b0a1.js"><link rel="prefetch" href="/assets/js/91.9c080a3d.js"><link rel="prefetch" href="/assets/js/92.2d7e99de.js"><link rel="prefetch" href="/assets/js/93.3a7c19cd.js"><link rel="prefetch" href="/assets/js/94.da299190.js"><link rel="prefetch" href="/assets/js/95.54d70fa0.js"><link rel="prefetch" href="/assets/js/96.68967f40.js"><link rel="prefetch" href="/assets/js/97.6ec5cb5a.js"><link rel="prefetch" href="/assets/js/98.4ce5bd4a.js"><link rel="prefetch" href="/assets/js/99.de11b345.js">
    <link rel="stylesheet" href="/assets/css/0.styles.e8e4f3a3.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><!---->  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><p>https://pytorch.org/tutorials/intermediate/ddp_tutorial.html</p> <p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel" target="_blank" rel="noopener noreferrer">DistributedDataParallel<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> (DDP) реализует параллелизм данных на уровне модулей, который может выполняться на нескольких компьютерах. Приложения, использующие DDP, должны порождать несколько процессов и создавать один экземпляр DDP для каждого процесса. DDP использует коллективные коммуникации в пакете <a href="https://pytorch.org/tutorials/intermediate/dist_tuto.html" target="_blank" rel="noopener noreferrer">torch.distributed<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> для синхронизации градиентов и буферов. В частности, DDP регистрирует хук автоградации для каждого параметра, заданного параметром, <code>model.parameters()</code>и хук срабатывает, когда соответствующий градиент вычисляется в обратном проходе. Затем DDP использует этот сигнал для запуска градиентной синхронизации между процессами. Дополнительные сведения см. в <a href="https://pytorch.org/docs/master/notes/ddp.html" target="_blank" rel="noopener noreferrer">примечаниях к дизайну DDP .<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>Рекомендуемый способ использования DDP — создание одного процесса для каждой реплики модели, при этом реплика модели может охватывать несколько устройств. Процессы DDP можно размещать на одном и том же компьютере или на нескольких компьютерах, но устройства GPU не могут быть общими для процессов. Это руководство начинается с базового варианта использования DDP, а затем демонстрирует более сложные варианты использования, включая модели с контрольными точками и объединение DDP с параллельными моделями.</p> <p>ПРИМЕЧАНИЕ</p> <p>Код в этом руководстве выполняется на сервере с 8 графическими процессорами, но его можно легко обобщить на другие среды.</p> <h2 id="сравнение-между-dataparallelиdistributeddataparallel"><a href="#сравнение-между-dataparallelиdistributeddataparallel" class="header-anchor">#</a> Сравнение между <code>DataParallel</code>и<code>DistributedDataParallel</code><a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#comparison-between-dataparallel-and-distributeddataparallel" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></h2> <p>Прежде чем мы углубимся, давайте проясним, почему, несмотря на дополнительную сложность, вы можете использовать <code>DistributedDataParallel</code>over <code>DataParallel</code>:</p> <ul><li><p>Во-первых, <code>DataParallel</code>это однопроцессный, многопоточный и работает только на одной машине, тогда как <code>DistributedDataParallel</code>он многопроцессный и работает как для одно-, так и для многомашинного обучения. <code>DataParallel</code>обычно медленнее, чем <code>DistributedDataParallel</code>даже на одной машине, из-за соперничества GIL между потоками, реплицированной модели для каждой итерации и дополнительных накладных расходов, связанных с разбрасыванием входных данных и сбором выходных данных.</p></li> <li><p>Напомним из <a href="https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html" target="_blank" rel="noopener noreferrer">предыдущего руководства<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> , что если ваша модель слишком велика для одного GPU, вы должны использовать <strong>параллельную модель</strong> , чтобы разделить ее на несколько GPU. <code>DistributedDataParallel</code>работает с <strong>моделью параллельно</strong> ; <code>DataParallel</code>в это время нет. Когда DDP сочетается с модельным параллелизмом, каждый процесс DDP будет использовать модельный параллелизм, а все процессы в совокупности будут использовать параллелизм данных.</p></li> <li><p>Если ваша модель должна охватывать несколько компьютеров или если ваш вариант использования не соответствует парадигме параллелизма данных, см. <a href="https://pytorch.org/docs/stable/rpc.html" target="_blank" rel="noopener noreferrer">RPC API<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> для более общей поддержки распределенного обучения.</p></li></ul> <h2 id="базовыи-вариант-использования"><a href="#базовыи-вариант-использования" class="header-anchor">#</a> Базовый вариант использования<a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#basic-use-case" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></h2> <p>Чтобы создать модуль DDP, вы должны сначала правильно настроить группы процессов. Более подробную информацию можно найти в <a href="https://pytorch.org/tutorials/intermediate/dist_tuto.html" target="_blank" rel="noopener noreferrer">Написание распределенных приложений с помощью PyTorch<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> .</p> <p>import os
import sys
import tempfile
import torch
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim
import torch.multiprocessing as mp</p> <p>from torch.nn.parallel import DistributedDataParallel as DDP</p> <h1 id="on-windows-platform-the-torch-distributed-package-only"><a href="#on-windows-platform-the-torch-distributed-package-only" class="header-anchor">#</a> On Windows platform, the torch.distributed package only</h1> <h1 id="supports-gloo-backend-filestore-and-tcpstore"><a href="#supports-gloo-backend-filestore-and-tcpstore" class="header-anchor">#</a> supports Gloo backend, FileStore and TcpStore.</h1> <h1 id="for-filestore-set-init-method-parameter-in-init-process-group"><a href="#for-filestore-set-init-method-parameter-in-init-process-group" class="header-anchor">#</a> For FileStore, set init_method parameter in init_process_group</h1> <h1 id="to-a-local-file-example-as-follow"><a href="#to-a-local-file-example-as-follow" class="header-anchor">#</a> to a local file. Example as follow:</h1> <h1 id="init-method-file-f-libtmp-some-file"><a href="#init-method-file-f-libtmp-some-file" class="header-anchor">#</a> init_method=&quot;file:///f:/libtmp/some_file&quot;</h1> <h1 id="dist-init-process-group"><a href="#dist-init-process-group" class="header-anchor">#</a> dist.init_process_group(</h1> <h1 id="gloo"><a href="#gloo" class="header-anchor">#</a> &quot;gloo&quot;,</h1> <h1 id="rank-rank"><a href="#rank-rank" class="header-anchor">#</a> rank=rank,</h1> <h1 id="init-method-init-method"><a href="#init-method-init-method" class="header-anchor">#</a> init_method=init_method,</h1> <h1 id="world-size-world-size"><a href="#world-size-world-size" class="header-anchor">#</a> world_size=world_size)</h1> <h1 id="for-tcpstore-same-way-as-on-linux"><a href="#for-tcpstore-same-way-as-on-linux" class="header-anchor">#</a> For TcpStore, same way as on Linux.</h1> <p>def setup(rank, world_size):
os.environ['MASTER_ADDR'] = 'localhost'
os.environ['MASTER_PORT'] = '12355'</p> <div class="language- extra-class"><pre><code># initialize the process group
dist.init_process_group(&quot;gloo&quot;, rank=rank, world_size=world_size)
</code></pre></div><p>def cleanup():
dist.destroy_process_group()</p> <p>Теперь давайте создадим игрушечный модуль, обернем его DDP и скормим ему фиктивные входные данные. Обратите внимание, что поскольку DDP передает состояния модели от процесса ранга 0 всем остальным процессам в конструкторе DDP, вам не нужно беспокоиться о том, что разные процессы DDP начинаются с разных начальных значений параметров модели.</p> <p>class ToyModel(nn.Module):
def <strong>init</strong>(self):
super(ToyModel, self).<strong>init</strong>()
self.net1 = nn.Linear(10, 10)
self.relu = nn.ReLU()
self.net2 = nn.Linear(10, 5)</p> <div class="language- extra-class"><pre><code>def forward(self, x):
    return self.net2(self.relu(self.net1(x)))
</code></pre></div><p>def demo_basic(rank, world_size):
print(f&quot;Running basic DDP example on rank {rank}.&quot;)
setup(rank, world_size)</p> <div class="language- extra-class"><pre><code># create model and move it to GPU with id rank
model = ToyModel().to(rank)
ddp_model = DDP(model, device_ids=[rank])

loss_fn = nn.MSELoss()
optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

optimizer.zero_grad()
outputs = ddp_model(torch.randn(20, 10))
labels = torch.randn(20, 5).to(rank)
loss_fn(outputs, labels).backward()
optimizer.step()

cleanup()
</code></pre></div><p>def run_demo(demo_fn, world_size):
mp.spawn(demo_fn,
args=(world_size,),
nprocs=world_size,
join=True)</p> <p>Как видите, DDP оборачивает детали распределенной связи более низкого уровня и предоставляет чистый API, как если бы это была локальная модель. Связь с синхронизацией градиента происходит во время обратного прохода и перекрывается с обратным вычислением. Когда <code>backward()</code>возвращается, <code>param.grad</code>уже содержит синхронизированный тензор градиента. В базовых случаях использования DDP требуется всего несколько дополнительных LoC для настройки группы процессов. При применении DDP к более сложным случаям использования следует соблюдать некоторые предостережения.</p> <h2 id="неравномерная-скорость-обработки"><a href="#неравномерная-скорость-обработки" class="header-anchor">#</a> Неравномерная скорость обработки<a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#skewed-processing-speeds" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></h2> <p>В DDP конструктор, прямой и обратный проходы являются распределенными точками синхронизации. Предполагается, что разные процессы запускают одинаковое количество синхронизаций, достигают этих точек синхронизации в одном и том же порядке и входят в каждую точку синхронизации примерно в одно и то же время. В противном случае быстрые процессы могут прибыть раньше и превысить время ожидания отставших. Следовательно, пользователи несут ответственность за балансировку распределения рабочей нагрузки между процессами. Иногда перекосы в скорости обработки неизбежны, например, из-за сетевых задержек, конфликтов за ресурсы или непредсказуемых скачков рабочей нагрузки. Чтобы избежать тайм-аутов в таких ситуациях, убедитесь, что вы передаете достаточно большое <code>timeout</code>значение при вызове <a href="https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group" target="_blank" rel="noopener noreferrer">init_process_group<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> .</p> <h2 id="сохранение-и-загрузка-контрольных-точек"><a href="#сохранение-и-загрузка-контрольных-точек" class="header-anchor">#</a> Сохранение и загрузка контрольных точек<a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#save-and-load-checkpoints" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></h2> <p><code>torch.save</code>Модули и <code>torch.load</code>контрольные точки обычно используются во время обучения и восстановления после контрольных точек. Подробнее см. в <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html" target="_blank" rel="noopener noreferrer">разделе СОХРАНЕНИЕ И ЗАГРУЗКА МОДЕЛЕЙ .<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> При использовании DDP одной из оптимизаций является сохранение модели только в одном процессе, а затем загрузка ее во все процессы, что снижает накладные расходы на запись. Это правильно, потому что все процессы начинаются с одних и тех же параметров, а градиенты синхронизируются в обратных проходах, и, следовательно, оптимизаторы должны продолжать устанавливать для параметров одни и те же значения. Если вы используете эту оптимизацию, убедитесь, что ни один процесс не начнет загружаться до завершения сохранения. Кроме того, при загрузке модуля необходимо предоставить соответствующий <code>map_location</code> аргумент, чтобы предотвратить доступ процесса к чужим устройствам. Если <code>map_location</code> отсутствует,<code>torch.load</code>сначала загрузит модуль в ЦП, а затем скопирует каждый параметр туда, где он был сохранен, что приведет к тому, что все процессы на одной машине будут использовать один и тот же набор устройств. Дополнительные сведения о восстановлении после сбоев и поддержке эластичности см. в <a href="https://pytorch.org/elastic" target="_blank" rel="noopener noreferrer">TorchElastic<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> .</p> <p>def demo_checkpoint(rank, world_size):
print(f&quot;Running DDP checkpoint example on rank {rank}.&quot;)
setup(rank, world_size)</p> <div class="language- extra-class"><pre><code>model = ToyModel().to(rank)
ddp_model = DDP(model, device_ids=[rank])

CHECKPOINT_PATH = tempfile.gettempdir() + &quot;/model.checkpoint&quot;
if rank == 0:
    # All processes should see same parameters as they all start from same
    # random parameters and gradients are synchronized in backward passes.
    # Therefore, saving it in one process is sufficient.
    torch.save(ddp_model.state_dict(), CHECKPOINT_PATH)

# Use a barrier() to make sure that process 1 loads the model after process
# 0 saves it.
dist.barrier()
# configure map_location properly
map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}
ddp_model.load_state_dict(
    torch.load(CHECKPOINT_PATH, map_location=map_location))

loss_fn = nn.MSELoss()
optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

optimizer.zero_grad()
outputs = ddp_model(torch.randn(20, 10))
labels = torch.randn(20, 5).to(rank)

loss_fn(outputs, labels).backward()
optimizer.step()

# Not necessary to use a dist.barrier() to guard the file deletion below
# as the AllReduce ops in the backward pass of DDP already served as
# a synchronization.

if rank == 0:
    os.remove(CHECKPOINT_PATH)

cleanup()
</code></pre></div><h2 id="сочетание-ddp-с-параллелизмом-моделеи"><a href="#сочетание-ddp-с-параллелизмом-моделеи" class="header-anchor">#</a> Сочетание DDP с параллелизмом моделей<a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#combining-ddp-with-model-parallelism" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></h2> <p>DDP также работает с моделями с несколькими графическими процессорами. DDP-обёртка моделей с несколькими GPU особенно полезна при обучении больших моделей с огромным объёмом данных.</p> <p>class ToyMpModel(nn.Module):
def <strong>init</strong>(self, dev0, dev1):
super(ToyMpModel, self).<strong>init</strong>()
self.dev0 = dev0
self.dev1 = dev1
self.net1 = torch.nn.Linear(10, 10).to(dev0)
self.relu = torch.nn.ReLU()
self.net2 = torch.nn.Linear(10, 5).to(dev1)</p> <div class="language- extra-class"><pre><code>def forward(self, x):
    x = x.to(self.dev0)
    x = self.relu(self.net1(x))
    x = x.to(self.dev1)
    return self.net2(x)
</code></pre></div><p>При передаче модели с несколькими графическими процессорами в DDP <code>device_ids</code>НЕ <code>output_device</code> ДОЛЖЕН устанавливаться. Входные и выходные данные будут помещены в соответствующие устройства либо приложением, либо <code>forward()</code>методом модели.</p> <p>def demo_model_parallel(rank, world_size):
print(f&quot;Running DDP with model parallel example on rank {rank}.&quot;)
setup(rank, world_size)</p> <div class="language- extra-class"><pre><code># setup mp_model and devices for this process
dev0 = (rank * 2) % world_size
dev1 = (rank * 2 + 1) % world_size
mp_model = ToyMpModel(dev0, dev1)
ddp_mp_model = DDP(mp_model)

loss_fn = nn.MSELoss()
optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)

optimizer.zero_grad()
# outputs will be on dev1
outputs = ddp_mp_model(torch.randn(20, 10))
labels = torch.randn(20, 5).to(dev1)
loss_fn(outputs, labels).backward()
optimizer.step()

cleanup()
</code></pre></div><p>if <strong>name</strong> == &quot;<strong>main</strong>&quot;:
n_gpus = torch.cuda.device_count()
assert n_gpus &gt;= 2, f&quot;Requires at least 2 GPUs to run, but got {n_gpus}&quot;
world_size = n_gpus
run_demo(demo_basic, world_size)
run_demo(demo_checkpoint, world_size)
run_demo(demo_model_parallel, world_size)</p> <h2 id="инициализируите-ddp-с-помощью-torch-distributed-run-torchrun"><a href="#инициализируите-ddp-с-помощью-torch-distributed-run-torchrun" class="header-anchor">#</a> Инициализируйте DDP с помощью torch.distributed.run/torchrun<a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#initialize-ddp-with-torch-distributed-run-torchrun" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></h2> <p>Мы можем использовать PyTorch Elastic, чтобы упростить код DDP и упростить инициализацию задания. Давайте все же воспользуемся примером Toymodel и создадим файл с именем <code>elastic_ddp.py</code>.</p> <p>import torch
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim</p> <p>from torch.nn.parallel import DistributedDataParallel as DDP</p> <p>class ToyModel(nn.Module):
def <strong>init</strong>(self):
super(ToyModel, self).<strong>init</strong>()
self.net1 = nn.Linear(10, 10)
self.relu = nn.ReLU()
self.net2 = nn.Linear(10, 5)</p> <div class="language- extra-class"><pre><code>def forward(self, x):
    return self.net2(self.relu(self.net1(x)))
</code></pre></div><p>def demo_basic():
dist.init_process_group(&quot;nccl&quot;)
rank = dist.get_rank()
print(f&quot;Start running basic DDP example on rank {rank}.&quot;)</p> <div class="language- extra-class"><pre><code># create model and move it to GPU with id rank
device_id = rank % torch.cuda.device_count()
model = ToyModel().to(device_id)
ddp_model = DDP(model, device_ids=[device_id])

loss_fn = nn.MSELoss()
optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

optimizer.zero_grad()
outputs = ddp_model(torch.randn(20, 10))
labels = torch.randn(20, 5).to(device_id)
loss_fn(outputs, labels).backward()
optimizer.step()
</code></pre></div><p>if <strong>name</strong> == &quot;<strong>main</strong>&quot;:
demo_basic()</p> <p>Затем можно запустить команду <a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#id1" target="_blank" rel="noopener noreferrer"><code>torch elastic/torchrun&lt;https://pytorch.org/docs/stable/elastic/quickstart.html&gt;</code>__<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> на всех узлах, чтобы инициализировать задание DDP, созданное выше:</p> <p>torchrun --nnodes=2 --nproc_per_node=8 --rdzv_id=100 --rdzv_backend=c10d --rdzv_endpoint=$MASTER_ADDR:29400 elastic_ddp.py</p> <p>Мы запускаем сценарий DDP на двух хостах, и на каждом хосте мы запускаем 8 процессов, то есть мы запускаем его на 16 графических процессорах. Обратите внимание, что они <code>$MASTER_ADDR</code>должны быть одинаковыми для всех узлов.</p> <p>Здесь torchrun запустит 8 процессов и вызовет <code>elastic_ddp.py</code> каждый процесс на узле, на котором он запущен, но пользователю также необходимо применить инструменты управления кластером, такие как slurm, чтобы фактически запустить эту команду на 2 узлах.</p> <p>Например, в кластере с поддержкой SLURM мы можем написать скрипт для запуска приведенной выше команды и установить его <code>MASTER_ADDR</code>как:</p> <p>export MASTER_ADDR=$(scontrol show hostname ${SLURM_NODELIST} | head -n 1)</p> <p>Затем мы можем просто запустить этот скрипт с помощью команды SLURM: . Конечно, это всего лишь пример; вы можете выбрать свои собственные инструменты планирования кластера, чтобы инициировать задание torchrun.<code>srun --nodes=2 ./torchrun_script.sh</code></p> <p>Для получения дополнительной информации об эластичном беге можно проверить этот <a href="https://pytorch.org/docs/stable/elastic/quickstart.html" target="_blank" rel="noopener noreferrer">документ с кратким руководством<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> , чтобы узнать больше.</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.dec9f71a.js" defer></script><script src="/assets/js/2.733019b2.js" defer></script><script src="/assets/js/28.f9359f93.js" defer></script>
  </body>
</html>
