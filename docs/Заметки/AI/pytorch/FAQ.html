<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>напиши как подготовить Dataset в pytorch | Obsidian notes</title>
    <meta name="generator" content="VuePress 1.9.9">
    
    <meta name="description" content="Obsidian notes">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    
    <link rel="preload" href="/doc_notes/assets/css/0.styles.60b82a90.css" as="style"><link rel="preload" href="/doc_notes/assets/js/app.d7b7570d.js" as="script"><link rel="preload" href="/doc_notes/assets/js/2.733019b2.js" as="script"><link rel="preload" href="/doc_notes/assets/js/29.0fdf0aa1.js" as="script"><link rel="prefetch" href="/doc_notes/assets/js/10.466a3961.js"><link rel="prefetch" href="/doc_notes/assets/js/100.eed12daa.js"><link rel="prefetch" href="/doc_notes/assets/js/101.c2c72797.js"><link rel="prefetch" href="/doc_notes/assets/js/102.3a5b3674.js"><link rel="prefetch" href="/doc_notes/assets/js/103.4df54047.js"><link rel="prefetch" href="/doc_notes/assets/js/104.4e3d031e.js"><link rel="prefetch" href="/doc_notes/assets/js/105.fb56ad64.js"><link rel="prefetch" href="/doc_notes/assets/js/106.4cd1492c.js"><link rel="prefetch" href="/doc_notes/assets/js/107.a916259a.js"><link rel="prefetch" href="/doc_notes/assets/js/108.dfbcdb35.js"><link rel="prefetch" href="/doc_notes/assets/js/109.b85d5957.js"><link rel="prefetch" href="/doc_notes/assets/js/11.70fc3590.js"><link rel="prefetch" href="/doc_notes/assets/js/110.dc40183f.js"><link rel="prefetch" href="/doc_notes/assets/js/111.a9f83101.js"><link rel="prefetch" href="/doc_notes/assets/js/112.1b402c16.js"><link rel="prefetch" href="/doc_notes/assets/js/113.89928947.js"><link rel="prefetch" href="/doc_notes/assets/js/114.8be0db96.js"><link rel="prefetch" href="/doc_notes/assets/js/115.bd9e24bd.js"><link rel="prefetch" href="/doc_notes/assets/js/116.1979db39.js"><link rel="prefetch" href="/doc_notes/assets/js/117.7a439523.js"><link rel="prefetch" href="/doc_notes/assets/js/118.680aed03.js"><link rel="prefetch" href="/doc_notes/assets/js/119.dfdba03a.js"><link rel="prefetch" href="/doc_notes/assets/js/12.0f945969.js"><link rel="prefetch" href="/doc_notes/assets/js/120.37c405a9.js"><link rel="prefetch" href="/doc_notes/assets/js/121.672a368b.js"><link rel="prefetch" href="/doc_notes/assets/js/122.f1b5fad1.js"><link rel="prefetch" href="/doc_notes/assets/js/123.b0d4c3db.js"><link rel="prefetch" href="/doc_notes/assets/js/124.7f08733e.js"><link rel="prefetch" href="/doc_notes/assets/js/125.619db48f.js"><link rel="prefetch" href="/doc_notes/assets/js/126.048ed0c7.js"><link rel="prefetch" href="/doc_notes/assets/js/127.cc65fb73.js"><link rel="prefetch" href="/doc_notes/assets/js/128.27591c7f.js"><link rel="prefetch" href="/doc_notes/assets/js/129.e848d5ea.js"><link rel="prefetch" href="/doc_notes/assets/js/13.353aee93.js"><link rel="prefetch" href="/doc_notes/assets/js/130.0b6325e2.js"><link rel="prefetch" href="/doc_notes/assets/js/131.a4a8dc74.js"><link rel="prefetch" href="/doc_notes/assets/js/132.f78488ea.js"><link rel="prefetch" href="/doc_notes/assets/js/133.2c57ab36.js"><link rel="prefetch" href="/doc_notes/assets/js/134.c041a644.js"><link rel="prefetch" href="/doc_notes/assets/js/135.dd89210d.js"><link rel="prefetch" href="/doc_notes/assets/js/136.127b0247.js"><link rel="prefetch" href="/doc_notes/assets/js/137.1ff783eb.js"><link rel="prefetch" href="/doc_notes/assets/js/138.e72eaf60.js"><link rel="prefetch" href="/doc_notes/assets/js/139.135c74d8.js"><link rel="prefetch" href="/doc_notes/assets/js/14.a3283f94.js"><link rel="prefetch" href="/doc_notes/assets/js/140.4a7f191d.js"><link rel="prefetch" href="/doc_notes/assets/js/141.fa563aa9.js"><link rel="prefetch" href="/doc_notes/assets/js/142.266c8a69.js"><link rel="prefetch" href="/doc_notes/assets/js/143.3c3e596e.js"><link rel="prefetch" href="/doc_notes/assets/js/144.46a5cdc6.js"><link rel="prefetch" href="/doc_notes/assets/js/145.c33d2f51.js"><link rel="prefetch" href="/doc_notes/assets/js/146.ecf9ffa3.js"><link rel="prefetch" href="/doc_notes/assets/js/147.ecc8f162.js"><link rel="prefetch" href="/doc_notes/assets/js/148.57a0cc2c.js"><link rel="prefetch" href="/doc_notes/assets/js/149.243334a6.js"><link rel="prefetch" href="/doc_notes/assets/js/15.c66e3407.js"><link rel="prefetch" href="/doc_notes/assets/js/150.6811595e.js"><link rel="prefetch" href="/doc_notes/assets/js/151.a1b33f48.js"><link rel="prefetch" href="/doc_notes/assets/js/152.754c44e2.js"><link rel="prefetch" href="/doc_notes/assets/js/153.b6b30dd0.js"><link rel="prefetch" href="/doc_notes/assets/js/154.78d410b8.js"><link rel="prefetch" href="/doc_notes/assets/js/155.767f3fb1.js"><link rel="prefetch" href="/doc_notes/assets/js/156.f9095760.js"><link rel="prefetch" href="/doc_notes/assets/js/157.c538a726.js"><link rel="prefetch" href="/doc_notes/assets/js/158.9835a2a3.js"><link rel="prefetch" href="/doc_notes/assets/js/159.9d7c5a05.js"><link rel="prefetch" href="/doc_notes/assets/js/16.e7ecc933.js"><link rel="prefetch" href="/doc_notes/assets/js/160.addf636e.js"><link rel="prefetch" href="/doc_notes/assets/js/161.b9499ae3.js"><link rel="prefetch" href="/doc_notes/assets/js/162.9ebe738a.js"><link rel="prefetch" href="/doc_notes/assets/js/163.4860d1e7.js"><link rel="prefetch" href="/doc_notes/assets/js/164.148cebf3.js"><link rel="prefetch" href="/doc_notes/assets/js/165.41046f67.js"><link rel="prefetch" href="/doc_notes/assets/js/166.6deaed29.js"><link rel="prefetch" href="/doc_notes/assets/js/167.6d02a205.js"><link rel="prefetch" href="/doc_notes/assets/js/168.c86d38a7.js"><link rel="prefetch" href="/doc_notes/assets/js/169.eb313225.js"><link rel="prefetch" href="/doc_notes/assets/js/17.65a71bb5.js"><link rel="prefetch" href="/doc_notes/assets/js/170.889855cd.js"><link rel="prefetch" href="/doc_notes/assets/js/171.b95cf306.js"><link rel="prefetch" href="/doc_notes/assets/js/172.0b1e5fe3.js"><link rel="prefetch" href="/doc_notes/assets/js/173.99679181.js"><link rel="prefetch" href="/doc_notes/assets/js/174.f28ad52f.js"><link rel="prefetch" href="/doc_notes/assets/js/175.1c1f371e.js"><link rel="prefetch" href="/doc_notes/assets/js/176.662a9d28.js"><link rel="prefetch" href="/doc_notes/assets/js/177.6e464bd5.js"><link rel="prefetch" href="/doc_notes/assets/js/178.102c88e4.js"><link rel="prefetch" href="/doc_notes/assets/js/179.dddab088.js"><link rel="prefetch" href="/doc_notes/assets/js/18.8fedcbac.js"><link rel="prefetch" href="/doc_notes/assets/js/180.345e741e.js"><link rel="prefetch" href="/doc_notes/assets/js/181.59db7110.js"><link rel="prefetch" href="/doc_notes/assets/js/182.7f628252.js"><link rel="prefetch" href="/doc_notes/assets/js/183.e8653839.js"><link rel="prefetch" href="/doc_notes/assets/js/184.3eec36ec.js"><link rel="prefetch" href="/doc_notes/assets/js/185.cb0c13d5.js"><link rel="prefetch" href="/doc_notes/assets/js/186.1ccbe1a2.js"><link rel="prefetch" href="/doc_notes/assets/js/187.55e6bc99.js"><link rel="prefetch" href="/doc_notes/assets/js/188.1829998b.js"><link rel="prefetch" href="/doc_notes/assets/js/189.e86e8099.js"><link rel="prefetch" href="/doc_notes/assets/js/19.8fd4f833.js"><link rel="prefetch" href="/doc_notes/assets/js/190.3263ca68.js"><link rel="prefetch" href="/doc_notes/assets/js/191.6973d93a.js"><link rel="prefetch" href="/doc_notes/assets/js/192.8c648d4c.js"><link rel="prefetch" href="/doc_notes/assets/js/193.135dc6c4.js"><link rel="prefetch" href="/doc_notes/assets/js/194.2387809d.js"><link rel="prefetch" href="/doc_notes/assets/js/195.4e094a48.js"><link rel="prefetch" href="/doc_notes/assets/js/196.faae151e.js"><link rel="prefetch" href="/doc_notes/assets/js/197.6ca84b2f.js"><link rel="prefetch" href="/doc_notes/assets/js/198.99d5a7c7.js"><link rel="prefetch" href="/doc_notes/assets/js/199.5ac6f260.js"><link rel="prefetch" href="/doc_notes/assets/js/20.b7871733.js"><link rel="prefetch" href="/doc_notes/assets/js/200.434715d2.js"><link rel="prefetch" href="/doc_notes/assets/js/201.df5e4553.js"><link rel="prefetch" href="/doc_notes/assets/js/202.4f5738c7.js"><link rel="prefetch" href="/doc_notes/assets/js/203.7bdee8f2.js"><link rel="prefetch" href="/doc_notes/assets/js/204.5b4e69e3.js"><link rel="prefetch" href="/doc_notes/assets/js/205.58586a6e.js"><link rel="prefetch" href="/doc_notes/assets/js/206.b5603313.js"><link rel="prefetch" href="/doc_notes/assets/js/207.e1a4577a.js"><link rel="prefetch" href="/doc_notes/assets/js/208.2369d699.js"><link rel="prefetch" href="/doc_notes/assets/js/209.baadeea1.js"><link rel="prefetch" href="/doc_notes/assets/js/21.1cff06fb.js"><link rel="prefetch" href="/doc_notes/assets/js/210.2b107173.js"><link rel="prefetch" href="/doc_notes/assets/js/211.c8eea835.js"><link rel="prefetch" href="/doc_notes/assets/js/212.1fae6417.js"><link rel="prefetch" href="/doc_notes/assets/js/213.5696d97f.js"><link rel="prefetch" href="/doc_notes/assets/js/214.bbd783da.js"><link rel="prefetch" href="/doc_notes/assets/js/215.1c0c350c.js"><link rel="prefetch" href="/doc_notes/assets/js/216.498044dc.js"><link rel="prefetch" href="/doc_notes/assets/js/217.319f81c6.js"><link rel="prefetch" href="/doc_notes/assets/js/218.8911d413.js"><link rel="prefetch" href="/doc_notes/assets/js/219.f37e96ea.js"><link rel="prefetch" href="/doc_notes/assets/js/22.2cd72a62.js"><link rel="prefetch" href="/doc_notes/assets/js/220.b5ac8e75.js"><link rel="prefetch" href="/doc_notes/assets/js/221.cde91cfa.js"><link rel="prefetch" href="/doc_notes/assets/js/222.df059246.js"><link rel="prefetch" href="/doc_notes/assets/js/223.3ce433b3.js"><link rel="prefetch" href="/doc_notes/assets/js/224.36f2c1ff.js"><link rel="prefetch" href="/doc_notes/assets/js/225.fbee00f9.js"><link rel="prefetch" href="/doc_notes/assets/js/226.306f0e70.js"><link rel="prefetch" href="/doc_notes/assets/js/227.4e7373a0.js"><link rel="prefetch" href="/doc_notes/assets/js/228.44fd0171.js"><link rel="prefetch" href="/doc_notes/assets/js/229.f832a1d6.js"><link rel="prefetch" href="/doc_notes/assets/js/23.e9957abc.js"><link rel="prefetch" href="/doc_notes/assets/js/230.043a91e9.js"><link rel="prefetch" href="/doc_notes/assets/js/231.7616cdd1.js"><link rel="prefetch" href="/doc_notes/assets/js/232.c3eb262d.js"><link rel="prefetch" href="/doc_notes/assets/js/233.645ff598.js"><link rel="prefetch" href="/doc_notes/assets/js/234.bb763bdf.js"><link rel="prefetch" href="/doc_notes/assets/js/235.f6724c17.js"><link rel="prefetch" href="/doc_notes/assets/js/236.2fe5969c.js"><link rel="prefetch" href="/doc_notes/assets/js/237.c379ae13.js"><link rel="prefetch" href="/doc_notes/assets/js/238.bc474d07.js"><link rel="prefetch" href="/doc_notes/assets/js/239.b4b3094b.js"><link rel="prefetch" href="/doc_notes/assets/js/24.e4e0f07a.js"><link rel="prefetch" href="/doc_notes/assets/js/240.b7298fad.js"><link rel="prefetch" href="/doc_notes/assets/js/241.edc191c3.js"><link rel="prefetch" href="/doc_notes/assets/js/242.d79274ed.js"><link rel="prefetch" href="/doc_notes/assets/js/243.db97328a.js"><link rel="prefetch" href="/doc_notes/assets/js/244.68cd4704.js"><link rel="prefetch" href="/doc_notes/assets/js/245.f501295b.js"><link rel="prefetch" href="/doc_notes/assets/js/246.ddc4d5d9.js"><link rel="prefetch" href="/doc_notes/assets/js/247.ff22cc5b.js"><link rel="prefetch" href="/doc_notes/assets/js/248.4a61cd51.js"><link rel="prefetch" href="/doc_notes/assets/js/249.be49f5ca.js"><link rel="prefetch" href="/doc_notes/assets/js/25.c7ae079a.js"><link rel="prefetch" href="/doc_notes/assets/js/250.43caa09e.js"><link rel="prefetch" href="/doc_notes/assets/js/251.26d5a6e9.js"><link rel="prefetch" href="/doc_notes/assets/js/252.b3bcf0c8.js"><link rel="prefetch" href="/doc_notes/assets/js/253.1a1b2b11.js"><link rel="prefetch" href="/doc_notes/assets/js/254.1c4090ef.js"><link rel="prefetch" href="/doc_notes/assets/js/255.a49e9f41.js"><link rel="prefetch" href="/doc_notes/assets/js/256.78de4e85.js"><link rel="prefetch" href="/doc_notes/assets/js/257.3f3d8408.js"><link rel="prefetch" href="/doc_notes/assets/js/258.2a59b276.js"><link rel="prefetch" href="/doc_notes/assets/js/259.8916e4fc.js"><link rel="prefetch" href="/doc_notes/assets/js/26.1ae4ceb3.js"><link rel="prefetch" href="/doc_notes/assets/js/260.9e38f578.js"><link rel="prefetch" href="/doc_notes/assets/js/261.bb658a8a.js"><link rel="prefetch" href="/doc_notes/assets/js/262.e3dc3020.js"><link rel="prefetch" href="/doc_notes/assets/js/263.f1020a9b.js"><link rel="prefetch" href="/doc_notes/assets/js/264.b8f1ff3a.js"><link rel="prefetch" href="/doc_notes/assets/js/265.d3eb13d8.js"><link rel="prefetch" href="/doc_notes/assets/js/266.f27ca21b.js"><link rel="prefetch" href="/doc_notes/assets/js/267.338c834f.js"><link rel="prefetch" href="/doc_notes/assets/js/268.b9ebda2b.js"><link rel="prefetch" href="/doc_notes/assets/js/269.dc7525cf.js"><link rel="prefetch" href="/doc_notes/assets/js/27.42caa565.js"><link rel="prefetch" href="/doc_notes/assets/js/270.137ed51c.js"><link rel="prefetch" href="/doc_notes/assets/js/271.b6fdb998.js"><link rel="prefetch" href="/doc_notes/assets/js/272.ddc1ee03.js"><link rel="prefetch" href="/doc_notes/assets/js/273.df6133aa.js"><link rel="prefetch" href="/doc_notes/assets/js/274.9115305d.js"><link rel="prefetch" href="/doc_notes/assets/js/275.13342d76.js"><link rel="prefetch" href="/doc_notes/assets/js/276.a9e1f1ec.js"><link rel="prefetch" href="/doc_notes/assets/js/277.f2728f30.js"><link rel="prefetch" href="/doc_notes/assets/js/278.7e726870.js"><link rel="prefetch" href="/doc_notes/assets/js/279.648ad6bd.js"><link rel="prefetch" href="/doc_notes/assets/js/28.45f1bbb9.js"><link rel="prefetch" href="/doc_notes/assets/js/280.720a2918.js"><link rel="prefetch" href="/doc_notes/assets/js/281.5a2d475b.js"><link rel="prefetch" href="/doc_notes/assets/js/282.62bc635b.js"><link rel="prefetch" href="/doc_notes/assets/js/283.ff6be5f5.js"><link rel="prefetch" href="/doc_notes/assets/js/284.3f7c0af1.js"><link rel="prefetch" href="/doc_notes/assets/js/285.c2f51624.js"><link rel="prefetch" href="/doc_notes/assets/js/286.a5b99138.js"><link rel="prefetch" href="/doc_notes/assets/js/287.829ac9bd.js"><link rel="prefetch" href="/doc_notes/assets/js/288.54aabaae.js"><link rel="prefetch" href="/doc_notes/assets/js/289.71b4d090.js"><link rel="prefetch" href="/doc_notes/assets/js/290.df175e90.js"><link rel="prefetch" href="/doc_notes/assets/js/291.014245fe.js"><link rel="prefetch" href="/doc_notes/assets/js/292.8d375ce2.js"><link rel="prefetch" href="/doc_notes/assets/js/293.8591ceba.js"><link rel="prefetch" href="/doc_notes/assets/js/294.d979d20b.js"><link rel="prefetch" href="/doc_notes/assets/js/295.372c2d39.js"><link rel="prefetch" href="/doc_notes/assets/js/296.07d572ab.js"><link rel="prefetch" href="/doc_notes/assets/js/297.5de1073e.js"><link rel="prefetch" href="/doc_notes/assets/js/298.5a6ac1ca.js"><link rel="prefetch" href="/doc_notes/assets/js/299.e87a7ab3.js"><link rel="prefetch" href="/doc_notes/assets/js/3.8087b6c9.js"><link rel="prefetch" href="/doc_notes/assets/js/30.33c143cb.js"><link rel="prefetch" href="/doc_notes/assets/js/300.c011f877.js"><link rel="prefetch" href="/doc_notes/assets/js/301.479875ba.js"><link rel="prefetch" href="/doc_notes/assets/js/302.fe22cf89.js"><link rel="prefetch" href="/doc_notes/assets/js/303.fe59bc5d.js"><link rel="prefetch" href="/doc_notes/assets/js/304.17566e0f.js"><link rel="prefetch" href="/doc_notes/assets/js/305.235d62da.js"><link rel="prefetch" href="/doc_notes/assets/js/306.6a899aaa.js"><link rel="prefetch" href="/doc_notes/assets/js/307.a6302576.js"><link rel="prefetch" href="/doc_notes/assets/js/308.53d18516.js"><link rel="prefetch" href="/doc_notes/assets/js/309.44746635.js"><link rel="prefetch" href="/doc_notes/assets/js/31.f3c83a33.js"><link rel="prefetch" href="/doc_notes/assets/js/310.2b0b41b5.js"><link rel="prefetch" href="/doc_notes/assets/js/311.a2425d85.js"><link rel="prefetch" href="/doc_notes/assets/js/312.ee8bb224.js"><link rel="prefetch" href="/doc_notes/assets/js/313.cdb7a074.js"><link rel="prefetch" href="/doc_notes/assets/js/314.5c46337b.js"><link rel="prefetch" href="/doc_notes/assets/js/315.d2f5d6ef.js"><link rel="prefetch" href="/doc_notes/assets/js/316.1d1b10d7.js"><link rel="prefetch" href="/doc_notes/assets/js/317.18978adf.js"><link rel="prefetch" href="/doc_notes/assets/js/318.725aaa9e.js"><link rel="prefetch" href="/doc_notes/assets/js/319.10c27323.js"><link rel="prefetch" href="/doc_notes/assets/js/32.2e4a5d25.js"><link rel="prefetch" href="/doc_notes/assets/js/320.be122112.js"><link rel="prefetch" href="/doc_notes/assets/js/321.21d59327.js"><link rel="prefetch" href="/doc_notes/assets/js/322.1c7aa8b5.js"><link rel="prefetch" href="/doc_notes/assets/js/323.61f2e664.js"><link rel="prefetch" href="/doc_notes/assets/js/324.d5ef212c.js"><link rel="prefetch" href="/doc_notes/assets/js/325.8dcaad1a.js"><link rel="prefetch" href="/doc_notes/assets/js/326.27ae755d.js"><link rel="prefetch" href="/doc_notes/assets/js/327.23295181.js"><link rel="prefetch" href="/doc_notes/assets/js/328.b1038029.js"><link rel="prefetch" href="/doc_notes/assets/js/329.685f438a.js"><link rel="prefetch" href="/doc_notes/assets/js/33.78d67de4.js"><link rel="prefetch" href="/doc_notes/assets/js/330.29d01e38.js"><link rel="prefetch" href="/doc_notes/assets/js/331.56ede5a6.js"><link rel="prefetch" href="/doc_notes/assets/js/332.26f5337e.js"><link rel="prefetch" href="/doc_notes/assets/js/333.7a1b5bed.js"><link rel="prefetch" href="/doc_notes/assets/js/334.ccc83ffa.js"><link rel="prefetch" href="/doc_notes/assets/js/335.dd4d24f2.js"><link rel="prefetch" href="/doc_notes/assets/js/336.5cd8a3be.js"><link rel="prefetch" href="/doc_notes/assets/js/337.725cd669.js"><link rel="prefetch" href="/doc_notes/assets/js/338.ca370789.js"><link rel="prefetch" href="/doc_notes/assets/js/339.4db35fe1.js"><link rel="prefetch" href="/doc_notes/assets/js/34.10602eab.js"><link rel="prefetch" href="/doc_notes/assets/js/340.11e5684e.js"><link rel="prefetch" href="/doc_notes/assets/js/341.87af888b.js"><link rel="prefetch" href="/doc_notes/assets/js/342.6288246d.js"><link rel="prefetch" href="/doc_notes/assets/js/343.10836901.js"><link rel="prefetch" href="/doc_notes/assets/js/344.85db1640.js"><link rel="prefetch" href="/doc_notes/assets/js/345.f1a97cf1.js"><link rel="prefetch" href="/doc_notes/assets/js/346.dd502824.js"><link rel="prefetch" href="/doc_notes/assets/js/347.b211385a.js"><link rel="prefetch" href="/doc_notes/assets/js/348.f255c270.js"><link rel="prefetch" href="/doc_notes/assets/js/349.36014517.js"><link rel="prefetch" href="/doc_notes/assets/js/35.03fbbb65.js"><link rel="prefetch" href="/doc_notes/assets/js/350.817bd0e1.js"><link rel="prefetch" href="/doc_notes/assets/js/351.abf45be4.js"><link rel="prefetch" href="/doc_notes/assets/js/352.4254451f.js"><link rel="prefetch" href="/doc_notes/assets/js/353.c0b15b9d.js"><link rel="prefetch" href="/doc_notes/assets/js/354.d725c37e.js"><link rel="prefetch" href="/doc_notes/assets/js/355.10f1ce9b.js"><link rel="prefetch" href="/doc_notes/assets/js/356.a5e2bfda.js"><link rel="prefetch" href="/doc_notes/assets/js/357.80f39a19.js"><link rel="prefetch" href="/doc_notes/assets/js/358.5c69b1d1.js"><link rel="prefetch" href="/doc_notes/assets/js/359.12d21c81.js"><link rel="prefetch" href="/doc_notes/assets/js/36.aa74ba81.js"><link rel="prefetch" href="/doc_notes/assets/js/360.1183658a.js"><link rel="prefetch" href="/doc_notes/assets/js/361.33b745b6.js"><link rel="prefetch" href="/doc_notes/assets/js/362.a56596c0.js"><link rel="prefetch" href="/doc_notes/assets/js/363.1fadef9e.js"><link rel="prefetch" href="/doc_notes/assets/js/364.e43e06a1.js"><link rel="prefetch" href="/doc_notes/assets/js/365.1b191379.js"><link rel="prefetch" href="/doc_notes/assets/js/366.77112bc2.js"><link rel="prefetch" href="/doc_notes/assets/js/367.cbbf1410.js"><link rel="prefetch" href="/doc_notes/assets/js/368.6e4af412.js"><link rel="prefetch" href="/doc_notes/assets/js/369.9d8214a4.js"><link rel="prefetch" href="/doc_notes/assets/js/37.bad965a6.js"><link rel="prefetch" href="/doc_notes/assets/js/370.5dcbc931.js"><link rel="prefetch" href="/doc_notes/assets/js/371.3e798a72.js"><link rel="prefetch" href="/doc_notes/assets/js/372.99fbe027.js"><link rel="prefetch" href="/doc_notes/assets/js/373.783fc78c.js"><link rel="prefetch" href="/doc_notes/assets/js/374.8fc2e9fe.js"><link rel="prefetch" href="/doc_notes/assets/js/375.2831b29c.js"><link rel="prefetch" href="/doc_notes/assets/js/376.8a690d9f.js"><link rel="prefetch" href="/doc_notes/assets/js/377.c6401c22.js"><link rel="prefetch" href="/doc_notes/assets/js/38.57a79422.js"><link rel="prefetch" href="/doc_notes/assets/js/39.7ab71035.js"><link rel="prefetch" href="/doc_notes/assets/js/4.da3ef268.js"><link rel="prefetch" href="/doc_notes/assets/js/40.ffa22594.js"><link rel="prefetch" href="/doc_notes/assets/js/41.b2fc54d1.js"><link rel="prefetch" href="/doc_notes/assets/js/42.c43bc930.js"><link rel="prefetch" href="/doc_notes/assets/js/43.5c93d7a1.js"><link rel="prefetch" href="/doc_notes/assets/js/44.605a54a6.js"><link rel="prefetch" href="/doc_notes/assets/js/45.f85a75a3.js"><link rel="prefetch" href="/doc_notes/assets/js/46.2cd25346.js"><link rel="prefetch" href="/doc_notes/assets/js/47.93f7d1a6.js"><link rel="prefetch" href="/doc_notes/assets/js/48.7fd0b6dc.js"><link rel="prefetch" href="/doc_notes/assets/js/49.c64bb839.js"><link rel="prefetch" href="/doc_notes/assets/js/5.dac787d8.js"><link rel="prefetch" href="/doc_notes/assets/js/50.d2fe7364.js"><link rel="prefetch" href="/doc_notes/assets/js/51.b9189617.js"><link rel="prefetch" href="/doc_notes/assets/js/52.4689b562.js"><link rel="prefetch" href="/doc_notes/assets/js/53.f0b1d96b.js"><link rel="prefetch" href="/doc_notes/assets/js/54.f52a48ab.js"><link rel="prefetch" href="/doc_notes/assets/js/55.98bfca4a.js"><link rel="prefetch" href="/doc_notes/assets/js/56.6c0a81f6.js"><link rel="prefetch" href="/doc_notes/assets/js/57.e17dfa82.js"><link rel="prefetch" href="/doc_notes/assets/js/58.f9a5000b.js"><link rel="prefetch" href="/doc_notes/assets/js/59.3296ea1c.js"><link rel="prefetch" href="/doc_notes/assets/js/6.2d0a63f8.js"><link rel="prefetch" href="/doc_notes/assets/js/60.610d4eca.js"><link rel="prefetch" href="/doc_notes/assets/js/61.64b18740.js"><link rel="prefetch" href="/doc_notes/assets/js/62.87e34293.js"><link rel="prefetch" href="/doc_notes/assets/js/63.fbd2d78b.js"><link rel="prefetch" href="/doc_notes/assets/js/64.493b857a.js"><link rel="prefetch" href="/doc_notes/assets/js/65.0a60479c.js"><link rel="prefetch" href="/doc_notes/assets/js/66.800419f9.js"><link rel="prefetch" href="/doc_notes/assets/js/67.343f5dab.js"><link rel="prefetch" href="/doc_notes/assets/js/68.fed77f78.js"><link rel="prefetch" href="/doc_notes/assets/js/69.8b1601da.js"><link rel="prefetch" href="/doc_notes/assets/js/7.c9d31aa2.js"><link rel="prefetch" href="/doc_notes/assets/js/70.aedd0ab9.js"><link rel="prefetch" href="/doc_notes/assets/js/71.b166238f.js"><link rel="prefetch" href="/doc_notes/assets/js/72.27a66c82.js"><link rel="prefetch" href="/doc_notes/assets/js/73.1d9b487f.js"><link rel="prefetch" href="/doc_notes/assets/js/74.84702901.js"><link rel="prefetch" href="/doc_notes/assets/js/75.2f6ae560.js"><link rel="prefetch" href="/doc_notes/assets/js/76.4856c210.js"><link rel="prefetch" href="/doc_notes/assets/js/77.9fc6950e.js"><link rel="prefetch" href="/doc_notes/assets/js/78.cb2f07a0.js"><link rel="prefetch" href="/doc_notes/assets/js/79.5e43d0b7.js"><link rel="prefetch" href="/doc_notes/assets/js/8.da9db8f9.js"><link rel="prefetch" href="/doc_notes/assets/js/80.d59ea8af.js"><link rel="prefetch" href="/doc_notes/assets/js/81.9fc53f43.js"><link rel="prefetch" href="/doc_notes/assets/js/82.5838801e.js"><link rel="prefetch" href="/doc_notes/assets/js/83.d2006fd2.js"><link rel="prefetch" href="/doc_notes/assets/js/84.9b965f14.js"><link rel="prefetch" href="/doc_notes/assets/js/85.de0c498b.js"><link rel="prefetch" href="/doc_notes/assets/js/86.ce67f8b8.js"><link rel="prefetch" href="/doc_notes/assets/js/87.5d47b003.js"><link rel="prefetch" href="/doc_notes/assets/js/88.eee9be64.js"><link rel="prefetch" href="/doc_notes/assets/js/89.42153946.js"><link rel="prefetch" href="/doc_notes/assets/js/9.0ccc34a6.js"><link rel="prefetch" href="/doc_notes/assets/js/90.13a9f4b2.js"><link rel="prefetch" href="/doc_notes/assets/js/91.832ae5d2.js"><link rel="prefetch" href="/doc_notes/assets/js/92.bd7c25ca.js"><link rel="prefetch" href="/doc_notes/assets/js/93.8a6f3f34.js"><link rel="prefetch" href="/doc_notes/assets/js/94.221348bd.js"><link rel="prefetch" href="/doc_notes/assets/js/95.86b48f96.js"><link rel="prefetch" href="/doc_notes/assets/js/96.7c6d0372.js"><link rel="prefetch" href="/doc_notes/assets/js/97.307341f8.js"><link rel="prefetch" href="/doc_notes/assets/js/98.14120c7c.js"><link rel="prefetch" href="/doc_notes/assets/js/99.40560c36.js">
    <link rel="stylesheet" href="/doc_notes/assets/css/0.styles.60b82a90.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/doc_notes/" class="home-link router-link-active"><!----> <span class="site-name">Obsidian notes</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/doc_notes/guide/" class="nav-link">
  Guide
</a></div><div class="nav-item"><a href="/doc_notes/config/" class="nav-link">
  Config
</a></div><div class="nav-item"><a href="https://v1.vuepress.vuejs.org" target="_blank" rel="noopener noreferrer" class="nav-link external">
  VuePress
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/doc_notes/guide/" class="nav-link">
  Guide
</a></div><div class="nav-item"><a href="/doc_notes/config/" class="nav-link">
  Config
</a></div><div class="nav-item"><a href="https://v1.vuepress.vuejs.org" target="_blank" rel="noopener noreferrer" class="nav-link external">
  VuePress
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="напиши-как-подготовить-dataset-в-pytorch"><a href="#напиши-как-подготовить-dataset-в-pytorch" class="header-anchor">#</a> напиши как подготовить Dataset в pytorch</h2> <p>To prepare a dataset in PyTorch, we can use the <code>Dataset</code> and <code>DataLoader</code> classes from the <code>torch.utils.data</code> module</p> <p>.The <code>Dataset</code> class is a PyTorch class that represents a dataset. It provides an interface to access the data and its labels one sample at a time. We can create our own custom dataset by subclassing the <code>Dataset</code> class or use one of the many built-in datasets provided by Torchvision</p> <p>.The <code>DataLoader</code> class is another PyTorch class that wraps an iterable over a dataset. It provides multi-process iterators that load data in parallel with the training process, which can speed up training significantly. The <code>DataLoader</code> knows nothing about the data but organizes it into batches and shuffles it for efficient training</p> <p>.Here's an example of how to prepare a custom dataset in PyTorch:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data 
<span class="token keyword">import</span> Dataset <span class="token keyword">class</span> <span class="token class-name">MyDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span> 
	<span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span> 
		self<span class="token punctuation">.</span>data <span class="token operator">=</span> data self<span class="token punctuation">.</span>labels <span class="token operator">=</span> labels 
	<span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> 
		<span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span> 
	<span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span> 
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span> 
		y <span class="token operator">=</span> self<span class="token punctuation">.</span>labels<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">return</span> x<span class="token punctuation">,</span> y
</code></pre></div><p>In this example, we define a custom dataset called <code>MyDataset</code>. The constructor takes two arguments: <code>data</code>, which is a list of input samples, and <code>labels</code>, which is a list of corresponding output labels. The <code>__len__()</code> method returns the length of the dataset (i.e., the number of samples), and the <code>__getitem__()</code> method returns a single sample and its label given an index.Once we have defined our custom dataset, we can use it to create a dataloader as follows:</p> <p><code>from torch.utils.data import DataLoader dataset = MyDataset(data, labels) dataloader = DataLoader(dataset, batch_size=32, shuffle=True)</code></p> <p>In this example, we first create an instance of our custom dataset using some input data (<code>data</code>) and corresponding output labels (<code>labels</code>). We then create a dataloader using this dataset with batch size 32 and shuffle set to True.We can now iterate over batches of samples in our dataloader during training as follows:</p> <p><code>for inputs, targets in dataloader: # Train model on batch of inputs and targets</code></p> <p>Here, each iteration returns two tensors: one containing a batch of input samples (<code>inputs</code>) and another containing their corresponding output labels (<code>targets</code>).</p> <h2 id="напиши-как-подготовить-датасет-с-текстами-в-pytorch"><a href="#напиши-как-подготовить-датасет-с-текстами-в-pytorch" class="header-anchor">#</a> напиши как подготовить датасет с текстами в pytorch</h2> <p>To prepare a dataset with texts in PyTorch, we can use the <code>torch.utils.data.Dataset</code> class to create a custom dataset. This class represents a dataset and provides an interface for accessing its samples. We can then use the <code>torch.utils.data.DataLoader</code> class to load the data in batches</p> <p><a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer">[1]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>.Here's an example of how to prepare a dataset with texts in PyTorch:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data 
<span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader 
<span class="token keyword">class</span> <span class="token class-name">TextDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span> 
	<span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> texts<span class="token punctuation">)</span><span class="token punctuation">:</span> 
		self<span class="token punctuation">.</span>texts <span class="token operator">=</span> texts 
	<span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> 
		<span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>texts<span class="token punctuation">)</span> 
	<span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span> 
		<span class="token keyword">return</span> self<span class="token punctuation">.</span>texts<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> 
<span class="token comment"># Example usage </span>
texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;This is the first text.&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;This is the second text.&quot;</span><span class="token punctuation">]</span> 
dataset <span class="token operator">=</span> TextDataset<span class="token punctuation">(</span>texts<span class="token punctuation">)</span> 
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">for</span> batch <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span>
</code></pre></div><p>In this example, we define a custom <code>TextDataset</code> class that takes a list of texts as input. The <code>__len__()</code> method returns the length of the dataset and the <code>__getitem__()</code> method returns a single sample from the dataset given an index.We then create an instance of this class with our list of texts and pass it to a <code>DataLoader</code> object. The <code>batch_size</code> parameter specifies how many samples per batch to load.Finally, we loop over each batch in the dataloader and print it out. In this case, since we only have two texts and set the batch size to 2, there will be only one batch.Note that before feeding these texts into a neural network model, they need to be converted into tensors using PyTorch's Tensor library</p> <p><a href="https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html" target="_blank" rel="noopener noreferrer">[2]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="noopener noreferrer">[3]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="модель-трансформера-для-извлечения-данных-из-html-страниц-с-примером-датасета"><a href="#модель-трансформера-для-извлечения-данных-из-html-страниц-с-примером-датасета" class="header-anchor">#</a> модель трансформера для извлечения данных из html страниц с примером датасета</h2> <p>Для извлечения данных из HTML страниц с примером датасета можно использовать фреймворк RASA NLU</p> <p><a href="https://mipt.ru/upload/medialibrary/e31/dissertation_baymurzina.pdf" target="_blank" rel="noopener noreferrer">[1]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>, который умеет распознавать намерения пользователя, а также извлекать сущности. AWS SageMaker<a href="https://aws.amazon.com/ru/blogs/rus/fine-tune-and-host-hugging-face-bert-models-on-amazon-sagemaker/" target="_blank" rel="noopener noreferrer">[2]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> - это служба, которую можно использовать, чтобы улу</p> <h2 id="что-из-себя-представляет-torchtext"><a href="#что-из-себя-представляет-torchtext" class="header-anchor">#</a> что из себя представляет torchtext</h2> <p><code>torchtext</code> - это библиотека для обработки естественного языка (Natural Language Processing, NLP) в PyTorch. Она позволяет легко загружать, обрабатывать и представлять текстовые данные для обучения моделей глубокого обучения.</p> <p>Основные возможности <code>torchtext</code> включают:</p> <ul><li>Поддержка различных форматов данных, таких как CSV, TSV, JSON и других.</li> <li>Поддержка обработки текста, включая токенизацию, создание словаря, индексацию и преобразование в векторы (embedding).</li> <li>Поддержка создания итераторов для загрузки данных в модель глубокого обучения. Это позволяет загружать данные по мере необходимости, что особенно важно для больших наборов данных.</li> <li>Поддержка многих задач NLP, включая классификацию текста, машинный перевод, генерацию текста и другие.</li></ul> <p><code>torchtext</code> предоставляет готовые функции и классы для обработки текстовых данных, что упрощает процесс подготовки данных для модели глубокого обучения. Благодаря этому можно быстро создавать и прототипировать модели для различных задач NLP.</p> <h2 id="нужно-написать-обучение-сети-на-pytorch-для-извлечения-данных-из-html-страниц-сдлеанныи-на-трансформерах-добавь-пример-датасет"><a href="#нужно-написать-обучение-сети-на-pytorch-для-извлечения-данных-из-html-страниц-сдлеанныи-на-трансформерах-добавь-пример-датасет" class="header-anchor">#</a> Нужно написать обучение сети на pytorch для извлечения данных из html страниц сдлеанный на трансформерах, добавь пример-датасет</h2> <p>Хорошо, я могу помочь вам с написанием обучения сети на PyTorch для извлечения данных из HTML страниц сделанных на трансформерах.</p> <p>Перед тем как начать обучение сети, вам понадобится подготовить датасет. Вот пример датасета:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset

<span class="token keyword">class</span> <span class="token class-name">HTMLDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer
        self<span class="token punctuation">.</span>max_length <span class="token operator">=</span> max_length

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        html_text <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'html'</span><span class="token punctuation">]</span>
        label <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>

        encoded_input <span class="token operator">=</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>encode_plus<span class="token punctuation">(</span>
            html_text<span class="token punctuation">,</span>
            add_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            max_length<span class="token operator">=</span>self<span class="token punctuation">.</span>max_length<span class="token punctuation">,</span>
            padding<span class="token operator">=</span><span class="token string">'max_length'</span><span class="token punctuation">,</span>
            truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            return_attention_mask<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            return_tensors<span class="token operator">=</span><span class="token string">'pt'</span>
        <span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">{</span>
            <span class="token string">'input_ids'</span><span class="token punctuation">:</span> encoded_input<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> encoded_input<span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'labels'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>label<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
</code></pre></div><p>В этом примере мы создаем класс <code>HTMLDataset</code>, который является наследником класса <code>Dataset</code> из PyTorch. В конструкторе класса мы передаем данные, токенизатор и максимальную длину для входной последовательности.</p> <p>Метод <code>__len__</code> возвращает количество элементов в датасете, а метод <code>__getitem__</code> возвращает словарь, содержащий закодированный входной текст, маску внимания и метку класса.</p> <p>Теперь, когда у нас есть датасет, мы можем приступить к написанию кода для обучения сети на PyTorch. Вот пример кода:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> transformers
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> random_split
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> AdamW

<span class="token comment"># Задаем параметры обучения</span>
batch_size <span class="token operator">=</span> <span class="token number">16</span>
epochs <span class="token operator">=</span> <span class="token number">3</span>
learning_rate <span class="token operator">=</span> <span class="token number">2e-5</span>
max_length <span class="token operator">=</span> <span class="token number">512</span>

<span class="token comment"># Загружаем датасет</span>
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token comment"># ваш датасет</span>

<span class="token comment"># Инициализируем токенизатор и модель</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-uncased'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-uncased'</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># Разбиваем датасет на обучающую и тестовую выборки</span>
train_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">-</span> train_size
train_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> random_split<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token punctuation">[</span>train_size<span class="token punctuation">,</span> test_size<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Инициализируем DataLoader для обучающей и тестовой выборок</span>
train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Инициализируем оптимизатор и функцию потерь</span>
optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Обучение модели</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        input_ids <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        attention_mask <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> attention_mask<span class="token operator">=</span>attention_mask<span class="token punctuation">,</span> labels<span class="token operator">=</span>labels<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
        logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits

        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># Оценка модели на тестовой выборке</span>
    correct_predictions <span class="token operator">=</span> <span class="token number">0</span>
    num_examples <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span>
        input_ids <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        attention_mask <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> attention_mask<span class="token operator">=</span>attention_mask<span class="token punctuation">,</span> labels<span class="token operator">=</span>labels<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
            logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits

        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        correct_predictions <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>preds <span class="token operator">==</span> labels<span class="token punctuation">)</span>
       
		num_examples <span class="token operator">+=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>

    test_accuracy <span class="token operator">=</span> correct_predictions <span class="token operator">/</span> num_examples
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">: Test accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>test_accuracy<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
</code></pre></div><h1 id="пример-датасета"><a href="#пример-датасета" class="header-anchor">#</a> Пример датасета</h1> <p>Вот простой пример датасета, содержащий два класса: &quot;положительный&quot; и &quot;отрицательный&quot;. Каждый элемент датасета представляет собой HTML-страницу и метку класса.</p> <div class="language-Python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">HTMLDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        html<span class="token punctuation">,</span> label <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        encoding <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>html<span class="token punctuation">,</span> max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'max_length'</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>
        input_ids <span class="token operator">=</span> encoding<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
        attention_mask <span class="token operator">=</span> encoding<span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> input_ids<span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> attention_mask<span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">:</span> label<span class="token punctuation">}</span>

data <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">'&lt;html&gt;&lt;body&gt;&lt;p&gt;Это положительный пример&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'&lt;html&gt;&lt;body&gt;&lt;p&gt;Это отрицательный пример&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'&lt;html&gt;&lt;body&gt;&lt;p&gt;Это еще один положительный пример&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'&lt;html&gt;&lt;body&gt;&lt;p&gt;Это еще один отрицательный пример&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

dataset <span class="token operator">=</span> HTMLDataset<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre></div><p>В этом примере мы создаем класс HTMLDataset, который наследуется от класса Dataset PyTorch. Класс HTMLDataset принимает список кортежей, где каждый кортеж содержит HTML-страницу и метку класса. Метод <strong>getitem</strong> класса HTMLDataset используется для преобразования HTML-страницы и метки класса в формат, который может быть использован моделью для обучения. Мы используем токенизатор, предоставленный библиотекой Hugging Face, чтобы превратить HTML-страницы в токены, которые можно использовать моделью. Мы также устанавливаем максимальную длину токенов, чтобы обрезать или заполнить токены до нужной длины.</p> <h2 id="write-pytorch-code-for-tweet-message-from-twetter-html-page-extraction-with-bert-model"><a href="#write-pytorch-code-for-tweet-message-from-twetter-html-page-extraction-with-bert-model" class="header-anchor">#</a> write pytorch code for tweet message from twetter html page extraction with bert model</h2> <p>Sure, here's an example PyTorch code for extracting tweet messages from a Twitter HTML page using the BERT model:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> requests
<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertTokenizer<span class="token punctuation">,</span> BertForSequenceClassification

<span class="token comment"># Load pre-trained BERT model</span>
model <span class="token operator">=</span> BertForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-uncased'</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-uncased'</span><span class="token punctuation">)</span>

<span class="token comment"># Define function for processing tweet messages</span>
<span class="token keyword">def</span> <span class="token function">process_tweet</span><span class="token punctuation">(</span>tweet<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Tokenize tweet message and convert to input IDs</span>
    input_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>tweet<span class="token punctuation">,</span> add_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># Convert input IDs to PyTorch tensor</span>
    input_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment"># Predict sentiment using BERT model</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span>
    _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    sentiment <span class="token operator">=</span> <span class="token string">'positive'</span> <span class="token keyword">if</span> predicted<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">'negative'</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">'message'</span><span class="token punctuation">:</span> tweet<span class="token punctuation">,</span> <span class="token string">'sentiment'</span><span class="token punctuation">:</span> sentiment<span class="token punctuation">}</span>

<span class="token comment"># Define function for extracting tweet messages from Twitter HTML page</span>
<span class="token keyword">def</span> <span class="token function">extract_tweets</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Make GET request to Twitter page and parse HTML content</span>
    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
    soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>
    <span class="token comment"># Find all tweet messages in HTML content</span>
    tweets <span class="token operator">=</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'p'</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'class'</span><span class="token punctuation">:</span> <span class="token string">'tweet-text'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment"># Process each tweet message using BERT model</span>
    processed_tweets <span class="token operator">=</span> <span class="token punctuation">[</span>process_tweet<span class="token punctuation">(</span>tweet<span class="token punctuation">.</span>text<span class="token punctuation">)</span> <span class="token keyword">for</span> tweet <span class="token keyword">in</span> tweets<span class="token punctuation">]</span>
    <span class="token keyword">return</span> processed_tweets

<span class="token comment"># Example usage</span>
url <span class="token operator">=</span> <span class="token string">'https://twitter.com/search?q=pytorch&amp;src=typed_query'</span>
tweets <span class="token operator">=</span> extract_tweets<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tweets<span class="token punctuation">)</span>
</code></pre></div><p>This code uses the <code>BertForSequenceClassification</code> model from the <code>transformers</code> library to classify the sentiment of each tweet message as either positive or negative. The <code>extract_tweets</code> function uses the <code>requests</code> and <code>BeautifulSoup</code> libraries to scrape the tweet messages from a Twitter HTML page, and then applies the <code>process_tweet</code> function to each message to classify its sentiment. The output is a list of dictionaries, each containing the original tweet message and its predicted sentiment.</p> <h2 id="i-need-example-of-text-extraction-from-another-text-made-with-pytorch-model"><a href="#i-need-example-of-text-extraction-from-another-text-made-with-pytorch-model" class="header-anchor">#</a> i need example of text extraction from another text made with pytorch model</h2> <p>Sure! Text extraction is a common task in natural language processing (NLP), and PyTorch is a popular framework for developing NLP models. Here's an example of how you can extract text from another text using a PyTorch model:</p> <div class="language-Python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> transformers

<span class="token comment"># Load the pre-trained model</span>
model <span class="token operator">=</span> transformers<span class="token punctuation">.</span>AutoModelForTokenClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># Load the tokenizer</span>
tokenizer <span class="token operator">=</span> transformers<span class="token punctuation">.</span>AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;bert-base-cased&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># Define the input text</span>
text <span class="token operator">=</span> <span class="token string">&quot;Barack Obama was born in Hawaii.&quot;</span>

<span class="token comment"># Tokenize the input text</span>
tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Convert the tokens to PyTorch tensors</span>
input_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>tokens<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
attention_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>tokens<span class="token punctuation">[</span><span class="token string">&quot;attention_mask&quot;</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
offset_mapping <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>tokens<span class="token punctuation">[</span><span class="token string">&quot;offset_mapping&quot;</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Make a forward pass through the model</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> attention_mask<span class="token punctuation">)</span>

<span class="token comment"># Get the predicted labels for each token</span>
predicted_labels <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># Extract the text corresponding to the predicted labels</span>
extracted_text <span class="token operator">=</span> <span class="token string">&quot;&quot;</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> label <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>predicted_labels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> label <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        start<span class="token punctuation">,</span> end <span class="token operator">=</span> offset_mapping<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        extracted_text <span class="token operator">+=</span> text<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">&quot; &quot;</span>

<span class="token comment"># Print the extracted text</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>extracted_text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>In this example, we're using a pre-trained BERT model fine-tuned on the CoNLL-2003 NER dataset to extract named entities from the input text. We first tokenize the input text using the BERT tokenizer, and then convert the tokens to PyTorch tensors to feed into the model. We then make a forward pass through the model to get the predicted labels for each token, and use these labels to extract the corresponding text from the input text. Finally, we print the extracted text.</p> <p>Note that this is just one example of text extraction using a PyTorch model, and there are many other types of models and tasks that can be used for text extraction.</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/doc_notes/assets/js/app.d7b7570d.js" defer></script><script src="/doc_notes/assets/js/2.733019b2.js" defer></script><script src="/doc_notes/assets/js/29.0fdf0aa1.js" defer></script>
  </body>
</html>
